<!DOCTYPE html>
<html lang="en-US">
  <head>
  <meta charset="utf-8">
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <link href="https://fonts.googleapis.com/css?family=Gaegu:300,700" rel="stylesheet">

  <!-- Enable responsiveness on mobile devices -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Share card -->
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@SeongminLeee" />
  <meta name="twitter:creator" content="@SeongminLeee" />
  <meta property="og:url" content="https://www.seongmin.xyz/" />
  <meta property="og:title" content="Seongmin Lee" />
  <meta property="og:description" content="Seongmin Lee is a PhD student at Georgia Tech developing visual explanations and scalable algorithms for responsible AI." />
  <meta property="og:image" content="http://www.seongmin.xyz/images/seongmin.jpg" />

  <title>
    
      High-Performance Transformers for Table Structure Recognition Need Early Convolutions — Seongmin Lee
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/styles.css">
  <!-- <link rel="stylesheet" href="styles.css"> -->
  <link href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" rel="stylesheet">

  <!-- Icons -->
  <!-- <a target="_blank" href="https://icons8.com/icon/Imv4VIewVo4o/sparkling">Shine</a> icon by <a target="_blank" href="https://icons8.com">Icons8</a> -->
  <link rel="apple-touch-icon" sizes="180x180" href="/icons/icons8-shine-ios-16-filled-32.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/icons/icons8-shine-ios-16-filled-32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/icons/icons8-shine-ios-16-filled-32.png">
  <!-- <link rel="manifest" href="/icons/site.webmanifest?v=xQdLjRyXLj"> -->
  <!-- <link rel="mask-icon" href="/icons/safari-pinned-tab.svg?v=xQdLjRyXLj" color="#313131"> -->
  <!-- <link rel="shortcut icon" href="/icons/favicon.ico?v=xQdLjRyXLj"> -->
  <meta name="msapplication-TileColor" content="#313131">
  <!-- <meta name="msapplication-config" content="/icons/browserconfig.xml?v=xQdLjRyXLj"> -->
  <meta name="theme-color" content="#ffffff">

  <!-- Feed -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Seongmin Lee" />

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-H9C1B1EYNC"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-H9C1B1EYNC');
  </script>

</head>

  <body>
    <header id="masthead">
	<h1>
  		<a href="/" title="Home">Seongmin Lee</a>
  		<!-- <div class="mastheadspacer"/></div> -->
   		<!-- <span class="masthead-slash">/</span> -->
   		<!-- <small>PhD Student at Georgia Tech</small> -->
		<!-- <a href="http://localhost:4000/cv"><div><i class="fa fa-portrait icon icon-right-space"></i>CV</div></a> -->
		<a href="http://localhost:4000/cv"><i class="fa fa-portrait icon icon-right-space"></i>CV</a>
	</h1>
	<nav>
		<!-- <a href="/cv">CV</a>
		<a href="/projects">Projects</a>
		<a href="/everything-else">Everything Else</a> -->
	</nav>
</header>
    <main>
      <div id="paper-title-wrapper" class="l-screen">

	<h1>High-Performance Transformers for Table Structure Recognition Need Early Convolutions</h1>

	<div id="venue-bar">
		<div id="venue">
			
			Oral Paper, Neural Information Processing Systems (NeurIPS) TRL Workshop (TRL), 2023
			
		</div>
		
		
		
		
		
	</div>

	<hr class="project-hr">

    <div id="author-wrapper">
        
            <div class="author">
                

    <!-- <a href="https://shengyun-peng.github.io/"> -->
        <img src="/images/people/shengyun-peng.jpeg" class="author-image">
    <!-- </a> -->


                
<a href="https://shengyun-peng.github.io/">ShengYun Peng</a>
            </div>
        
            <div class="author">
                

    <!-- <a href="https://www.seongmin.xyz/"> -->
        <img src="/images/people/seongmin-lee.jpg" class="author-image">
    <!-- </a> -->


                
<a href="https://www.seongmin.xyz/">Seongmin Lee</a>
            </div>
        
            <div class="author">
                

    <!-- <a href="https://www.linkedin.com/in/xiaojing-wang-x00788/"> -->
        <img src="/images/people/xiaojing-wang.jpeg" class="author-image">
    <!-- </a> -->


                
<a href="https://www.linkedin.com/in/xiaojing-wang-x00788/">Xiaojing Wang</a>
            </div>
        
            <div class="author">
                

    <!-- <a href="https://www.linkedin.com/in/rajarajeswari-raji-balasubramaniyan-ph-d-753792a8/"> -->
        <img src="/images/people/raji-balasubramaniyan.jpeg" class="author-image">
    <!-- </a> -->


                
<a href="https://www.linkedin.com/in/rajarajeswari-raji-balasubramaniyan-ph-d-753792a8/">Rajarajeswari Balasubramaniyan</a>
            </div>
        
            <div class="author">
                

    <!-- <a href="https://www.cc.gatech.edu/~dchau"> -->
        <img src="/images/people/polo-chau.jpg" class="author-image">
    <!-- </a> -->


                
<a href="https://www.cc.gatech.edu/~dchau">Duen Horng (Polo) Chau</a>
            </div>
        
    </div>

	<!-- <hr class="project-hr"> -->

	<div id="paper-materials" class="l-text">
		
		
			
		
			
			  <a href="/papers/tsr-convstem"><div><i class="fas fa-link" aria-hidden="true"></i> Project</div></a>
			
		
			
		
			
			  <a href="https://arxiv.org/pdf/2311.05565.pdf"><div><i class="far fa-file-pdf" aria-hidden="true"></i> PDF</div></a>
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
			  <a href="https://github.com/poloclub/tsr-convstem"><div><i class="fas fa-code" aria-hidden="true"></i> Code</div></a>
			
		
			
		
			
		
			
			
		
	</div>

</div>

<h2>Abstract</h2>
<div><p>Table structure recognition (TSR) aims to convert tabular images into a machine- readable format, where a visual encoder extracts image features and a textual decoder generates table-representing tokens. Existing approaches use classic con- volutional neural network (CNN) backbones for the visual encoder and transform- ers for the textual decoder. However, this hybrid CNN-Transformer architecture introduces a complex visual encoder that accounts for nearly half of the total model parameters, markedly reduces both training and inference speed, and hinders the potential for self-supervised learning in TSR. In this work, we design a lightweight visual encoder for TSR without sacrificing expressive power. We discover that a convolutional stem can match classic CNN backbone performance, with a much simpler model. The convolutional stem strikes an optimal balance between two crucial factors for high-performance TSR: a higher receptive field (RF) ratio and a longer sequence length. This allows it to “see” an appropriate portion of the table and “store” the complex table structure within sufficient context length for the sub- sequent transformer. We conducted reproducible ablation studies and open-sourced our code at https://github.com/poloclub/tsr-convstem to enhance transparency, in- spire innovations, and facilitate fair comparisons in our domain as tables are a promising modality for representation learning.</p>
</div>


<figure class="l-text">
    <img class="single" src="/images/papers/23-tsr-convstem.png">
    <figcaption class="single"></figcaption>
</figure>


<h2>BibTeX</h2>

<div class="highlighter-rouge bibtex bibtex-wrapper">
	<div class="highlight">
		<pre>
			
@article{peng2023high,
  title={High-Performance Transformers for Table Structure Recognition Need Early Convolutions},
  author={Peng, ShengYun and Lee, Seongmin and Wang, Xiaojing and Balasubramaniyan, Rajarajeswari and Chau, Duen Horng},
  journal={arXiv preprint arXiv:2311.05565},
  year={2023}
}
		</pre>
	</div>
</div>


    </main>
    <footer>
	<div id="footer-left">
		<a href="mailto:seongmin@gatech.edu"><i class="fa-lg fa fa-envelope footer-icon" aria-hidden="true"></i></a>
		<a href="https://twitter.com/SeongminLeee"><i class="fa-lg fab fa-twitter footer-icon" aria-hidden="true"></i></a>
		<a href="https://github.com/ligi214"><i class="fa-lg fab fa-github footer-icon" aria-hidden="true"></i></a>
		<a href="https://www.linkedin.com/in/seongmin-lee-8b8a97209/"><i class="fa-lg fab fa-linkedin-in footer-icon" aria-hidden="true"></i></a>
		<a href="https://scholar.google.com/citations?user=EA4jKm4AAAAJ&hl=ko&authuser=1"><i class="fa-lg fa fa-graduation-cap footer-icon" aria-hidden="true"></i></a>
		<br>
		<br>
		&copy; <time datetime="November 3, 2024">2024</time> Seongmin Lee
	</div>
	<div id="footer-right">
		Seongmin Lee is a PhD student at Georgia Tech developing visual explanations and scalable algorithms for responsible AI.
	</div>
</footer>

  </body>
  
</html>
