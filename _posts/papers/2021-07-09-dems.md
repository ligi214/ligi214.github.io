---
layout: paper
categories: papers
permalink: papers/dems
id: dems
title: "Unsupervised multi-source domain adaptation with no observable source data"
authors:
    - Hyunsik Jeon
    - Seongmin Lee
    - U Kang
venue: Public Library of Science
venue-shorthand: PLOS ONE
year: 2021
url: /papers/dems
pdf: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0253415
code: https://github.com/snudatalab/DEMS
type: journal
bibtex: |-

    @article{jeon2021unsupervised,
        title={Unsupervised multi-source domain adaptation with no observable source data},
        author={Jeon, Hyunsik and Lee, Seongmin and Kang, U},
        journal={Plos one},
        volume={16},
        number={7},
        pages={e0253415},
        year={2021},
        publisher={Public Library of Science San Francisco, CA USA}
    }
---

Given trained models from multiple source domains, how can we predict the labels of unlabeled data in a target domain? Unsupervised multi-source domain adaptation (UMDA) aims for predicting the labels of unlabeled target data by transferring the knowledge of multiple source domains. UMDA is a crucial problem in many real-world scenarios where no labeled target data are available. Previous approaches in UMDA assume that data are observable over all domains. However, source data are not easily accessible due to privacy or confidentiality issues in a lot of practical scenarios, although classifiers learned in source domains are readily available. In this work, we target data-free UMDA where source data are not observable at all, a novel problem that has not been studied before despite being very realistic and crucial. To solve data-free UMDA, we propose DEMS (Data-free Exploitation of Multiple Sources), a novel architecture that adapts target data to source domains without exploiting any source data, and estimates the target labels by exploiting pre-trained source classifiers. Extensive experiments for data-free UMDA on real-world datasets show that DEMS provides the state-of-the-art accuracy which is up to 27.5% point higher than that of the best baseline.